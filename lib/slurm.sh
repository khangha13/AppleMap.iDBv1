#!/bin/bash
# =============================================================================
# SLURM JOB MANAGEMENT UTILITIES FOR GATK PIPELINE
# =============================================================================
# SLURM job management functions used across all pipeline steps

# Function to create SLURM script from template
create_slurm_script() {
    local template="$1"
    local config="$2"
    local output="$3"
    local dataset_name="$4"
    local step_name="$5"
    local pipeline_root="$6"
    
    log_info "Creating SLURM script: $output"

    if [ ! -f "$template" ]; then
        log_error "SLURM template not found: $template"
        return 1
    fi

    if [ -z "$pipeline_root" ]; then
        log_error "PIPELINE_ROOT not provided to create_slurm_script"
        return 1
    fi

    local output_dir
    output_dir="$(dirname "$output")"
    if ! mkdir -p "$output_dir"; then
        log_error "Failed to create output directory: $output_dir"
        return 1
    fi
    
    if [ ! -d "$output_dir" ]; then
        log_error "Output directory does not exist after creation: $output_dir"
        return 1
    fi
    
    # Parse configuration using safer method
    declare -A config_map=()
    while IFS='=' read -r key value; do
        [ -z "$key" ] && continue
        # Handle values that may contain '=' by taking everything after first '='
        if [[ "$key" == *"="* ]]; then
            # This shouldn't happen with proper config format, but handle it
            continue
        fi
        config_map["$key"]="$value"
    done <<< "$config"
    
    # Extract configuration values with defaults
    local job_name="${config_map[job_name]:-}"
    local account="${config_map[account]:-}"
    local partition="${config_map[partition]:-}"
    local nodes="${config_map[nodes]:-}"
    local ntasks="${config_map[ntasks]:-}"
    local cpus_per_task="${config_map[cpus_per_task]:-}"
    local time_limit="${config_map[time_limit]:-}"
    local memory="${config_map[memory]:-}"
    local array_max="${config_map[array_max]:-}"
    local qos="${config_map[qos]:-}"
    
    # Validate required fields
    local missing_fields=()
    [ -z "$job_name" ] && missing_fields+=("job_name")
    [ -z "$account" ] && missing_fields+=("account")
    [ -z "$partition" ] && missing_fields+=("partition")
    [ -z "$nodes" ] && missing_fields+=("nodes")
    [ -z "$ntasks" ] && missing_fields+=("ntasks")
    [ -z "$cpus_per_task" ] && missing_fields+=("cpus_per_task")
    [ -z "$time_limit" ] && missing_fields+=("time_limit")
    [ -z "$memory" ] && missing_fields+=("memory")
    [ -z "$array_max" ] && missing_fields+=("array_max")
    
    if [ ${#missing_fields[@]} -gt 0 ]; then
        log_error "Missing required SLURM config fields: ${missing_fields[*]}"
        return 1
    fi
    
    # Create SLURM script header
    if ! cat > "$output" << EOF
#!/bin/bash -l
#SBATCH --job-name=${job_name}
#SBATCH --ntasks=${ntasks}
#SBATCH --account=${account}
#SBATCH --partition=${partition}
#SBATCH --nodes=${nodes}
#SBATCH --cpus-per-task=${cpus_per_task}
#SBATCH --time=${time_limit}
#SBATCH --mem=${memory}
#SBATCH --array=0-${array_max}
#SBATCH -o ${LOG_BASE_PATH}/${dataset_name}/${step_name}_%A_%a_%x_%j.output
#SBATCH -e ${LOG_BASE_PATH}/${dataset_name}/${step_name}_%A_%a_%x_%j.error

# =============================================================================
# SLURM-GENERATED SCRIPT FOR APPLE GATK PIPELINE - ${step_name^^}
# =============================================================================
# Generated by bin/gatk_pipeline.sh on $(date)
# Dataset: ${dataset_name}
# Array Range: 0-${array_max}
# SLURM Config: ${cpus_per_task} CPUs, ${memory} RAM, ${time_limit} time
# =============================================================================

EOF
    then
        log_error "Failed to write SLURM script header to: $output"
        return 1
    fi
    
    local py_bin="${PYTHON_BIN:-python3}"
    if ! command -v "$py_bin" >/dev/null 2>&1; then
        py_bin="python"
    fi
    # Use stdin ("-") to avoid Python treating the template path as a script file
    if ! "$py_bin" - <<'PY' "$template" "$output" "$pipeline_root"; then
import sys
template, output, pipeline_root = sys.argv[1:4]
with open(template, encoding="utf-8") as src:
    lines = src.readlines()
with open(output, "a", encoding="utf-8") as dst:
    for line in lines[1:]:
        if line.startswith("PIPELINE_ROOT=") and "BASH_SOURCE" in line:
            dst.write(f'PIPELINE_ROOT="{pipeline_root}"\n')
        else:
            dst.write(line.replace("__PIPELINE_ROOT_PLACEHOLDER__", pipeline_root))
PY
        log_error "Failed to append template body from $template to $output"
        return 1
    fi
    
    # Verify the file was created successfully
    if [ ! -f "$output" ]; then
        log_error "SLURM script file was not created: $output"
        return 1
    fi
    
    if [ ! -s "$output" ]; then
        log_error "SLURM script file is empty: $output"
        return 1
    fi
    
    # Make it executable
    if ! chmod +x "$output"; then
        log_error "Failed to make script executable: $output"
        return 1
    fi
    
    log_info "âœ“ Created SLURM script: $output"
    log_info "  Job name: $job_name"
    log_info "  Array range: 0-${array_max}"
    log_info "  SLURM config: ${cpus_per_task} CPUs, ${memory} RAM, ${time_limit} time"
}

# Function to submit job with logging
submit_job() {
    local script="$1"
    local params="$2"
    local dataset_name="$3"
    local step_name="$4"
    
    log_info "Submitting $step_name job: $script with parameters: $params"

    # Note: File existence check removed - create_slurm_script() already verifies
    # the file exists before returning. On network filesystems, immediate checks
    # can fail due to metadata caching even though the file exists.

    # Create log directory
    mkdir -p "${LOG_BASE_PATH}/${dataset_name}"
    log_info "Created SLURM log directory: ${LOG_BASE_PATH}/${dataset_name}"
    
    # Submit the job
    # Resolve script to absolute path to avoid path resolution issues
    # Strip any trailing newlines and whitespace that might come from command substitution
    local script_clean
    script_clean=$(printf '%s' "$script" | tr -d '\n\r' | sed 's/[[:space:]]*$//' | head -n1)
    
    # Get absolute path - check if already absolute first
    local script_abs
    if [[ "$script_clean" = /* ]]; then
        # Already absolute path - use it directly
        script_abs="$script_clean"
    else
        # Relative path - resolve it
        local script_dir script_file
        script_dir="$(cd "$(dirname "$script_clean")" 2>/dev/null && pwd)"
        if [ $? -ne 0 ] || [ -z "$script_dir" ]; then
            log_error "Failed to resolve script directory for: $script_clean"
            return 1
        fi
        script_file="$(basename "$script_clean")"
        script_abs="${script_dir}/${script_file}"
    fi
    
    local export_arg="--export=ALL"
    if [ -n "${PIPELINE_ROOT:-}" ]; then
        export_arg="${export_arg},PIPELINE_ROOT=${PIPELINE_ROOT}"
    fi
    if [ -n "${PIPELINE_ENV_FILE:-}" ]; then
        export_arg="${export_arg},PIPELINE_ENV_FILE=${PIPELINE_ENV_FILE}"
    fi
    if [ -n "${PIPELINE_DIR_NAME:-}" ]; then
        export_arg="${export_arg},PIPELINE_DIR_NAME=${PIPELINE_DIR_NAME}"
    fi
    if [ -n "${PIPELINE_HOME_CANDIDATE:-}" ]; then
        export_arg="${export_arg},PIPELINE_HOME_CANDIDATE=${PIPELINE_HOME_CANDIDATE}"
    fi
    if [ -n "${PIPELINE_LOG_DIR_OVERRIDE:-}" ]; then
        export_arg="${export_arg},PIPELINE_LOG_DIR_OVERRIDE=${PIPELINE_LOG_DIR_OVERRIDE}"
    fi
    
    local sbatch_output
    if ! sbatch_output=$(sbatch --parsable "${export_arg}" "$script_abs" $params 2>&1); then
        log_error "Failed to submit $step_name job via sbatch: ${sbatch_output}"
        log_error "Script path attempted: ${script_abs}"
        return 1
    fi
    local job_id
    job_id="$(printf '%s\n' "$sbatch_output" | head -n1 | cut -d';' -f1 | tr -d '\r')"
    if [ -z "${job_id}" ]; then
        log_error "sbatch returned empty job ID (raw output: ${sbatch_output})"
        return 1
    fi
    
    log_info "$step_name job submitted successfully - Job ID: $job_id"
    echo "$job_id"
}

# Function to monitor job status
monitor_job() {
    local job_id="$1"
    local timeout="${2:-3600}"  # Default 1 hour timeout
    
    log_info "Monitoring job: $job_id"
    
    local start_time=$(date +%s)
    local end_time=$((start_time + timeout))
    
    while [ $(date +%s) -lt $end_time ]; do
        if ! squeue -j "$job_id" >/dev/null 2>&1; then
            log_info "Job $job_id completed"
            return 0
        fi
        
        log_debug "Job $job_id still running..."
        sleep 60  # Check every minute
    done
    
    log_warn "Job $job_id monitoring timed out after $timeout seconds"
    return 1
}

# Function to get job status
get_job_status() {
    local job_id="$1"
    
    if ! squeue -j "$job_id" >/dev/null 2>&1; then
        echo "COMPLETED"
    else
        local status=$(squeue -j "$job_id" --noheader --format="%.2T" 2>/dev/null)
        echo "${status:-UNKNOWN}"
    fi
}

# Function to cancel job
cancel_job() {
    local job_id="$1"
    
    log_info "Cancelling job: $job_id"
    
    if scancel "$job_id"; then
        log_info "Job $job_id cancelled successfully"
        return 0
    else
        log_error "Failed to cancel job $job_id"
        return 1
    fi
}

# Function to get job information
get_job_info() {
    local job_id="$1"
    
    log_info "Getting job information for: $job_id"
    
    if scontrol show job "$job_id" >/dev/null 2>&1; then
        scontrol show job "$job_id"
    else
        log_warn "Job $job_id not found or completed"
        return 1
    fi
}

# Function to get user input with validation
get_user_input() {
    local prompt=$1
    local default=$2
    local input
    
    if [ -n "$default" ]; then
        read -p "$prompt [$default]: " input
        input=${input:-$default}
    else
        read -p "$prompt: " input
    fi
    
    echo "$input"
}

# Function to confirm before proceeding
confirm_action() {
    local message=$1
    local response
    
    while true; do
        read -p "$message (y/n): " response
        case $response in
            [Yy]* ) return 0;;
            [Nn]* ) return 1;;
            * ) echo "Please answer yes or no.";;
        esac
    done
}
